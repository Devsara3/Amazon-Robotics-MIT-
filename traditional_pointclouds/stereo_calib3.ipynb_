{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"14HLGMEe1WuW5oAyrMPdS42x8FiLRaO9x","timestamp":1767599782483},{"file_id":"1woCLBYW2s58n4v0FkDJN_PnfwZbYeQPy","timestamp":1767599657074},{"file_id":"1zHPaFo37VTDKdMqrzEQIcvbjJVOMOI4_","timestamp":1767575209400}],"gpuType":"T4","authorship_tag":"ABX9TyNvxqvQLozoWPWrgIBHLU2e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Stereo Vision Pipeline for Disparity Map Estimation\n","\n","This notebook describes the complete pipeline for computing disparity maps using a stereo camera system.\n","The goal is to improve the quality and robustness of disparity estimation by refining each processing step,\n","including camera calibration, image rectification, distortion correction, and post-processing.\n","\n","The pipeline consists of the following steps:\n","\n","1. Disparity map computation using StereoSGBM\n","2. Disparity map computation with hole-filling post-processing\n","3. Improved camera calibration (estimation of intrinsic parameters and distortion coefficients)\n","4. Verification and tuning of distortion correction using calibration parameters\n","5. Image rectification and undistortion\n","6. Disparity map computation using rectified and undistorted images\n","\n","Each step is explained below with its purpose and role in the overall pipeline."],"metadata":{"id":"7ia932UEsxae"}},{"cell_type":"markdown","source":["## 3. Improved Camera Calibration with Parameter Refinement\n","\n","Based on the baseline evaluation, an improved calibration approach is applied.\n","\n","In this step, calibration images with large reprojection errors\n","are selectively removed from the dataset.\n","This reduces the influence of noisy or inaccurate corner detections.\n","\n","By recalculating camera intrinsic parameters and distortion coefficients\n","using the refined dataset, more stable and accurate calibration results\n","can be obtained.\n","\n","This improvement directly contributes to better distortion correction\n","and more reliable stereo rectification.\n"],"metadata":{"id":"98ojmcbW_qfE"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import glob\n","import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","\n","CHECKERBOARD = (7, 7)\n","SQUARE_SIZE = 1.41\n","IMG_DIR = \"/content/drive/MyDrive/Amazon project/chess\"\n","\n","\n","objp = np.zeros((CHECKERBOARD[0]*CHECKERBOARD[1], 3), np.float32)\n","objp[:, :2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n","objp *= SQUARE_SIZE\n","\n","objpoints = []\n","imgpoints = []\n","valid_files = []\n","\n","\n","image_files = sorted(glob.glob(os.path.join(IMG_DIR, \"*.jpg\")))\n","if len(image_files) == 0:\n","    raise RuntimeError(\"‚ùå ÁîªÂÉè„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì\")\n","\n","# ================= corner detection =================\n","criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n","\n","for fname in image_files:\n","    img = cv2.imread(fname)\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, None)\n","    if ret:\n","        corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n","        objpoints.append(objp)\n","        imgpoints.append(corners2)\n","        valid_files.append(fname)\n","\n","print(f\"„Ç≥„Éº„Éä„ÉºÊ§úÂá∫ÊàêÂäüÁîªÂÉèÊï∞: {len(valid_files)} / {len(image_files)}\")\n","\n","# ================= calibration =================\n","flags = cv2.CALIB_FIX_K3\n","\n","ret, K, D, rvecs, tvecs = cv2.calibrateCamera(\n","    objpoints, imgpoints, gray.shape[::-1], None, None, flags=flags\n",")\n","\n","print(\"\\n=== ÊîπÂñÑÂâç ===\")\n","print(\"ÂÜçÊäïÂΩ±Ë™§Â∑Æ:\", ret)\n","print(\"ÂÜÖÈÉ®„Éë„É©„É°„Éº„Çø K:\\n\", K)\n","print(\"Ê≠™„Åø‰øÇÊï∞ D:\\n\", D.ravel())\n","\n","\n","filtered_objpoints = []\n","filtered_imgpoints = []\n","\n","for i in range(len(objpoints)):\n","    proj, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], K, D)\n","    error = cv2.norm(imgpoints[i], proj, cv2.NORM_L2) / len(proj)\n","\n","    if error <= 3.0:\n","        filtered_objpoints.append(objpoints[i])\n","        filtered_imgpoints.append(imgpoints[i])\n","\n","print(f\"‰ΩøÁî®ÁîªÂÉèÊï∞Ôºà„Éï„Ç£„É´„ÇøÂæåÔºâ: {len(filtered_objpoints)} / {len(objpoints)}\")\n","\n","# ================re-calibration==================\n","ret, K, D, rvecs, tvecs = cv2.calibrateCamera(\n","    filtered_objpoints,\n","    filtered_imgpoints,\n","    gray.shape[::-1],\n","    None,\n","    None,\n","    flags=flags\n",")\n","\n","print(\"\\n=== ÊîπÂñÑÂæåÔºàÊúÄÁµÇÁµêÊûúÔºâ===\")\n","print(\"ÊúÄÁµÇÂÜçÊäïÂΩ±Ë™§Â∑Æ:\", ret)\n","print(\"ÊúÄÁµÇÂÜÖÈÉ®„Éë„É©„É°„Éº„Çø K:\\n\", K)\n","print(\"ÊúÄÁµÇÊ≠™„Åø‰øÇÊï∞ D:\\n\", D.ravel())\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QF1Jg4R-Bkiq","executionInfo":{"status":"ok","timestamp":1767595002473,"user_tz":-540,"elapsed":5406,"user":{"displayName":"Êø±Áî∞Á¥óÁ©∫","userId":"17631605000964168817"}},"outputId":"372ee119-f012-412f-bd7c-b2e78711e9c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","„Ç≥„Éº„Éä„ÉºÊ§úÂá∫ÊàêÂäüÁîªÂÉèÊï∞: 30 / 30\n","\n","=== ÊîπÂñÑÂâç ===\n","ÂÜçÊäïÂΩ±Ë™§Â∑Æ: 1.3658356973155437\n","ÂÜÖÈÉ®„Éë„É©„É°„Éº„Çø K:\n"," [[1.15994113e+03 0.00000000e+00 5.46000399e+02]\n"," [0.00000000e+00 1.15929016e+03 7.32384585e+02]\n"," [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n","Ê≠™„Åø‰øÇÊï∞ D:\n"," [ 7.68506874e-03 -1.33669015e-01 -5.20174312e-05  4.92592454e-04\n","  0.00000000e+00]\n","‰ΩøÁî®ÁîªÂÉèÊï∞Ôºà„Éï„Ç£„É´„ÇøÂæåÔºâ: 30 / 30\n","\n","=== ÊîπÂñÑÂæåÔºàÊúÄÁµÇÁµêÊûúÔºâ===\n","ÊúÄÁµÇÂÜçÊäïÂΩ±Ë™§Â∑Æ: 1.3658356973155437\n","ÊúÄÁµÇÂÜÖÈÉ®„Éë„É©„É°„Éº„Çø K:\n"," [[1.15994113e+03 0.00000000e+00 5.46000399e+02]\n"," [0.00000000e+00 1.15929016e+03 7.32384585e+02]\n"," [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n","ÊúÄÁµÇÊ≠™„Åø‰øÇÊï∞ D:\n"," [ 7.68506874e-03 -1.33669015e-01 -5.20174312e-05  4.92592454e-04\n","  0.00000000e+00]\n"]}]},{"cell_type":"markdown","source":["## 4. Distortion Parameter Tuning and Verification\n","\n","In this step, the estimated distortion parameters are further tuned\n","to improve visual and geometric consistency.\n","\n","Using the refined calibration parameters:\n","- Image undistortion is applied\n","- Straight lines in the scene are checked for curvature\n","- Checkerboard patterns are inspected for geometric correctness\n","\n","Parameter tuning is performed iteratively to minimize residual distortion,\n","especially near image edges.\n","\n","This final verification ensures that the calibrated parameters\n","are suitable for rectification and disparity map computation.\n"],"metadata":{"id":"yp9ujjlY7To0"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import glob\n","import os\n","from google.colab import drive\n","from google.colab.patches import cv2_imshow\n","\n","# ==============================\n","#  Google Drive „Éû„Ç¶„É≥„Éà\n","# ==============================\n","drive.mount('/content/drive')\n","\n","# ==============================\n","#  „Éë„ÇπË®≠ÂÆö\n","# ==============================\n","IMG_DIR = \"/content/drive/MyDrive/Amazon project/chess\"\n","OUTPUT_DIR = os.path.join(IMG_DIR, \"processed\")\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# ==============================\n","#  „Ç´„É°„É©„Éë„É©„É°„Éº„ÇøÔºàÂâçÂõû„Ç≠„É£„É™„Éñ„É¨„Éº„Ç∑„Éß„É≥ÁµêÊûúÔºâ\n","# ==============================\n","\n","K = np.array([\n","    [1.15994113e+03, 0.00000000e+00, 5.46000399e+02],\n"," [0.00000000e+00, 1.15929016e+03, 7.32384585e+02],\n"," [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]\n",", dtype=np.float64)\n","\n","\n","D = 0.32 * np.array( [ 7.68506874e-03, -1.33669015e-01, -5.20174312e-05,  4.92592454e-04,\n","  0.00000000e+00], dtype=np.float64)\n","\n","\n","# ==============================\n","# üìå ÁîªÂÉè„É™„Çπ„ÉàÂèñÂæó\n","# ==============================\n","image_files = sorted(glob.glob(os.path.join(IMG_DIR, \"*.jpg\")))\n","if len(image_files) == 0:\n","    print(\"‚ùå ÁîªÂÉè„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ„Éë„Çπ„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\")\n","\n","# ==============================\n","# üìå Ê≠™„ÅøË£úÊ≠£ÔºàUndistortÔºâ + ROIÂàá„ÇäÂèñ„Çä\n","# ==============================\n","for fname in image_files:\n","    img = cv2.imread(fname)\n","    if img is None:\n","        print(f\"‚ùå Ë™≠„ÅøËæº„ÅøÂ§±Êïó: {fname}\")\n","        continue\n","\n","    h, w = img.shape[:2]\n","\n","    # Êñ∞„Åó„ÅÑ„Ç´„É°„É©Ë°åÂàóÔºàÁ´Ø„ÅÆÈÅéÂâ∞Ë£úÊ≠£Èò≤Ê≠¢ alpha=0Ôºâ\n","    new_K, roi = cv2.getOptimalNewCameraMatrix(K, D, (w, h), alpha=0)\n","\n","    # Ê≠™„ÅøË£úÊ≠£\n","    undistorted = cv2.undistort(img, K, D, None, new_K)\n","\n","    # ROI„ÅßÂàá„ÇäÂèñ„Çä\n","    x, y, w_roi, h_roi = roi\n","    undistorted = undistorted[y:y+h_roi, x:x+w_roi]\n","\n","    # Ë°®Á§∫ÔºàÁ¢∫Ë™çÁî®Ôºâ\n","    print(f\"Ë£úÊ≠£ÂæåÁîªÂÉè: {os.path.basename(fname)}\")\n","    cv2_imshow(undistorted)\n","\n","    # ‰øùÂ≠ò\n","    save_path = os.path.join(OUTPUT_DIR, os.path.basename(fname))\n","    cv2.imwrite(save_path, undistorted)\n","\n","print(\" ÂÖ®ÁîªÂÉè„ÅÆÊ≠™„ÅøË£úÊ≠£ÂÆå‰∫Ü\")\n"],"metadata":{"id":"KB-uhrWNLP59"},"execution_count":null,"outputs":[]}]}
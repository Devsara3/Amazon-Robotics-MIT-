{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1woCLBYW2s58n4v0FkDJN_PnfwZbYeQPy","timestamp":1767599657074},{"file_id":"1zHPaFo37VTDKdMqrzEQIcvbjJVOMOI4_","timestamp":1767575209400}],"gpuType":"T4","authorship_tag":"ABX9TyOhSRopo/ahHi+32uwQptBu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Stereo Vision Pipeline for Disparity Map Estimation\n","\n","This notebook describes the complete pipeline for computing disparity maps using a stereo camera system.\n","The goal is to improve the quality and robustness of disparity estimation by refining each processing step,\n","including camera calibration, image rectification, distortion correction, and post-processing.\n","\n","The pipeline consists of the following steps:\n","\n","1. Disparity map computation using StereoSGBM\n","2. Disparity map computation with hole-filling post-processing\n","3. Improved camera calibration (estimation of intrinsic parameters and distortion coefficients)\n","4. Verification and tuning of distortion correction using calibration parameters\n","5. Image rectification and undistortion\n","6. Disparity map computation using rectified and undistorted images\n","\n","Each step is explained below with its purpose and role in the overall pipeline."],"metadata":{"id":"7ia932UEsxae"}},{"cell_type":"markdown","source":["## 2.2. Validation of Calibration Parameters Using the Baseline Method\n","\n","In this step, camera intrinsic parameters and distortion coefficients\n","are estimated using a standard calibration method without additional filtering.\n","\n","To evaluate the reliability of these parameters, distortion correction\n","is applied to the original images using the estimated values.\n","The checkerboard is then reprojected onto the undistorted images.\n","\n","This process allows us to assess calibration quality by observing:\n","\n","- Alignment between projected points and actual checkerboard corners\n","- Residual distortion near image boundaries\n","- Visual consistency across different calibration images\n","\n","This baseline evaluation serves as a reference for later improvements.\n"],"metadata":{"id":"980HlcSb9Im3"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import glob\n","from google.colab.patches import cv2_imshow\n","from google.colab import drive\n","\n","\n","drive.mount('/content/drive')\n","\n","\n","CHECKERBOARD = (7, 7)\n","SQUARE_SIZE = 1.41\n","IMG_DIR = \"/content/drive/MyDrive/Amazon project/chess\"\n","\n","\n","objp = np.zeros((CHECKERBOARD[0]*CHECKERBOARD[1],3), np.float32)\n","objp[:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1,2)\n","objp *= SQUARE_SIZE\n","\n","objpoints = []  # 3Dポイント\n","imgpoints = []  # 2Dポイント\n","\n","# ===== 画像読み込み =====\n","image_files = glob.glob(IMG_DIR + \"/*.jpg\")\n","if len(image_files) == 0:\n","    print(\"画像が見つかりません。パスを確認してください。\")\n","\n","# ===== コーナー検出 =====\n","for fname in image_files:\n","    img = cv2.imread(fname)\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, None)\n","    if ret:\n","        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n","        corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n","\n","        objpoints.append(objp)\n","        imgpoints.append(corners2)\n","\n","        # # コーナーを描画して確認\n","        # cv2.drawChessboardCorners(img, CHECKERBOARD, corners2, ret)\n","        # cv2_imshow(img)\n","    else:\n","        print(f\"コーナー検出失敗: {fname}\")\n","\n","# ===== カメラキャリブレーション =====\n","ret, K, D, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n","print(\"再投影誤差:\", ret)\n","print(\"カメラ行列:\\n\", K)\n","print(\"歪み係数:\\n\", D)\n","\n","D_n= 0.05 * D\n","# ===== 最適カメラ行列（端の過剰補正を抑える alpha=0） =====\n","new_K, roi = cv2.getOptimalNewCameraMatrix(K, D_n, gray.shape[::-1], alpha=0)\n","\n","# ===== 歪み補正 =====\n","for fname in image_files:\n","    img = cv2.imread(fname)\n","    undistorted = cv2.undistort(img, K, D_n, None, new_K)\n","\n","    # ROIで切り取り（必要に応じて）\n","    x, y, w_roi, h_roi = roi\n","    undistorted = undistorted[y:y+h_roi, x:x+w_roi]\n","\n","    # 表示\n","    print(f\"補正後画像: {fname}\")\n","    cv2_imshow(undistorted)\n","\n","    # 保存する場合\n","    save_path = fname.replace(\"chess\", \"chess/processed\")\n","    cv2.imwrite(save_path, undistorted)"],"metadata":{"id":"Rzkm6zjiLYaZ"},"execution_count":null,"outputs":[]}]}